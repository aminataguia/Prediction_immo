{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model training script\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading dataset and cleaning it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in the dataset: ['Unnamed: 0', 'id_transaction', 'date_transaction', 'prix', 'departement', 'id_ville', 'ville', 'code_postal', 'adresse', 'type_batiment', 'vefa', 'n_pieces', 'surface_habitable', 'id_parcelle_cadastre', 'latitude', 'longitude', 'surface_dependances', 'surface_locaux_industriels', 'surface_terrains_agricoles', 'surface_terrains_sols', 'surface_terrains_nature']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "df = pd.read_csv('transactions.csv')\n",
    "\n",
    "all_columns = df.columns.tolist()\n",
    "print(\"Columns in the dataset:\", all_columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing and Feature Engineering for Paris Real Estate Price Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new feature 'prix_m2'\n",
    "df['prix_m2'] = df['prix'] / df['surface_habitable']\n",
    "\n",
    "# Filter for Paris data in 2022\n",
    "idf_df = df[(df['departement'].isin([75, 77, 78, 91, 92, 93, 94, 95])) & (df['date_transaction'].str.startswith('2022-'))].copy()\n",
    "\n",
    "# Modify the features to exclude the 'date_transaction' column\n",
    "X = idf_df[['code_postal', 'n_pieces', 'surface_habitable', 'latitude', 'longitude']]\n",
    "\n",
    "# Add one-hot encoding for the 'date_transaction' column\n",
    "X = pd.concat([X, pd.get_dummies(idf_df['date_transaction'], prefix='date')], axis=1)\n",
    "\n",
    "# Define target variable\n",
    "y = idf_df['prix_m2']\n",
    "\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "    # Create transformers for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Create a column transformer to apply transformations to the appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ])\n",
    "\n",
    "    # Create a pipeline that first transforms the data and then fits the model\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # Preprocess the features\n",
    "X_processed = model_pipeline.fit_transform(X)\n",
    "\n",
    "    # Identify categorical and numerical columns\n",
    "categorical_cols = [col for col in X.columns if X[col].dtype == 'object']\n",
    "numerical_cols = [col for col in X.columns if X[col].dtype in ['int64', 'float64']]\n",
    "\n",
    "    # Create transformers for numerical and categorical data\n",
    "numerical_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "    # Create a column transformer to apply transformations to the appropriate columns\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "     ])\n",
    "\n",
    "    # Create a pipeline that first transforms the data and then fits the model\n",
    "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor)])\n",
    "\n",
    "    # Preprocess the features\n",
    "X_processed = model_pipeline.fit_transform(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the features\n",
    "X_processed = model_pipeline.fit_transform(X)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.8, random_state=42)\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.8, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'Unnamed: 0' in df.columns:\n",
    "   df = df.drop('Unnamed: 0', axis=1)\n",
    "    \n",
    "df['prix_m2'] = df['prix'] / (df['surface_habitable'])\n",
    "\n",
    "idf_df = df[(df.departement == 75) & (df.n_pieces == 4) & (df.date_transaction.str.startswith('2022-'))]\n",
    "surface_cols = [c for c in idf_df.columns if 'surface_' in c and c != 'surface_habitable']\n",
    "for c in surface_cols:\n",
    "     idf_df[c + '_sum'] = idf_df[c].apply(lambda x: sum(eval(x)) if 'NULL' not in x else 0)\n",
    "idf_df = idf_df[idf_df[[c + '_sum' for c in surface_cols]].sum(axis=1) == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import models + training, outil de prediction , de maniere lineaire "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Price per m2 for the new data: 8324.14119041518\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "\n",
    "# Chargez le modèle depuis le fichier .pkl en mode binaire\n",
    "with open('regression_model.pkl', 'rb') as model_file:\n",
    "    loaded_model = pickle.load(model_file)\n",
    "\n",
    "# Exemple de nouvelles données pour les prédictions\n",
    "new_data = pd.DataFrame({\n",
    "    'code_postal': [75001],\n",
    "    'n_pieces': [3],\n",
    "    'surface_habitable': [80],\n",
    "    'latitude': [48.8566],\n",
    "    'longitude': [2.3522],\n",
    "    'date_transaction': ['2022-01-01']\n",
    "})\n",
    "\n",
    "# Appliquez le même prétraitement sur les nouvelles données\n",
    "new_data_processed = model_pipeline.transform(new_data)\n",
    "\n",
    "# Faites des prédictions sur les nouvelles données à l'aide du modèle chargé\n",
    "predicted_price_per_m2 = loaded_model.predict(new_data_processed)\n",
    "\n",
    "print(f'Predicted Price per m2 for the new data: {predicted_price_per_m2[0]}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [01:04<02:08, 64.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: DTR\n",
      "Optimal params: {'max_depth': 1, 'min_samples_split': 2}\n",
      "Train RMSE: 26419.737018819014\n",
      "Test RMSE: 18480.923721835952\n",
      "Model Score: 0.019721920908795654\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [04:58<02:44, 164.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: KNN\n",
      "Optimal params: {'n_neighbors': 51}\n",
      "Train RMSE: 26086.0212611758\n",
      "Test RMSE: 18689.18914151\n",
      "Model Score: -0.0024964896546602056\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [06:55<00:00, 138.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: LR\n",
      "Optimal params: {'fit_intercept': True, 'positive': False}\n",
      "Train RMSE: 26396.75607753689\n",
      "Test RMSE: 18730.929715018374\n",
      "Model Score: -0.0069794563922978\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "params_grid = {\n",
    "    'DTR': {\n",
    "        'model': DecisionTreeRegressor(),\n",
    "        'params': {\n",
    "            'max_depth': (1, 101, 10),\n",
    "            'min_samples_split': (2, 21, 2)\n",
    "        }\n",
    "    },\n",
    "    'KNN': {\n",
    "        'model': KNeighborsRegressor(),\n",
    "        'params': {\n",
    "            'n_neighbors': (1, 51, 5)\n",
    "        }\n",
    "    },\n",
    "    'LR': {\n",
    "        'model': LinearRegression(),\n",
    "        'params': {\n",
    "            'fit_intercept': [True, False],\n",
    "            'positive': [True, False]\n",
    "        }}}\n",
    "\n",
    "for model_name, model_config in tqdm(params_grid.items()):\n",
    "    gs = GridSearchCV(estimator=model_config['model'], param_grid=model_config['params'])\n",
    "    # gs = GridSearchCV(estimator=model_config['model'], param_grid=model_config['params'], n_jobs=-1)\n",
    "    gs.fit(X_train, y_train)\n",
    "    best_model = gs.best_estimator_\n",
    "    best_params = gs.best_params_\n",
    "    train_rmse = np.sqrt(mean_squared_error(y_train, best_model.predict(X_train)))\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, best_model.predict(X_test)))\n",
    "    score = best_model.score(X_test, y_test)\n",
    "\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Optimal params: {best_params}\") \n",
    "    print(f\"Train RMSE: {train_rmse}\")\n",
    "    print(f\"Test RMSE: {test_rmse}\")\n",
    "    print(f\"Model Score: {score}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "asyncio.run() cannot be called from a running event loop",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessage\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlaceholder pour la prédiction immobilière\u001b[39m\u001b[38;5;124m\"\u001b[39m}  \u001b[38;5;66;03m# Placeholder pour le code réel\u001b[39;00m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 11\u001b[0m     \u001b[43muvicorn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mapp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhost\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m127.0.0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m8002\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python311\\Lib\\site-packages\\uvicorn\\main.py:587\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(app, host, port, uds, fd, loop, http, ws, ws_max_size, ws_max_queue, ws_ping_interval, ws_ping_timeout, ws_per_message_deflate, lifespan, interface, reload, reload_dirs, reload_includes, reload_excludes, reload_delay, workers, env_file, log_config, log_level, access_log, proxy_headers, server_header, date_header, forwarded_allow_ips, root_path, limit_concurrency, backlog, limit_max_requests, timeout_keep_alive, timeout_graceful_shutdown, ssl_keyfile, ssl_certfile, ssl_keyfile_password, ssl_version, ssl_cert_reqs, ssl_ca_certs, ssl_ciphers, headers, use_colors, app_dir, factory, h11_max_incomplete_event_size)\u001b[0m\n\u001b[0;32m    585\u001b[0m     Multiprocess(config, target\u001b[38;5;241m=\u001b[39mserver\u001b[38;5;241m.\u001b[39mrun, sockets\u001b[38;5;241m=\u001b[39m[sock])\u001b[38;5;241m.\u001b[39mrun()\n\u001b[0;32m    586\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 587\u001b[0m     \u001b[43mserver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39muds \u001b[38;5;129;01mand\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(config\u001b[38;5;241m.\u001b[39muds):\n\u001b[0;32m    589\u001b[0m     os\u001b[38;5;241m.\u001b[39mremove(config\u001b[38;5;241m.\u001b[39muds)  \u001b[38;5;66;03m# pragma: py-win32\u001b[39;00m\n",
      "File \u001b[1;32mc:\\python311\\Lib\\site-packages\\uvicorn\\server.py:62\u001b[0m, in \u001b[0;36mServer.run\u001b[1;34m(self, sockets)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m, sockets: \u001b[38;5;28mlist\u001b[39m[socket\u001b[38;5;241m.\u001b[39msocket] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39msetup_event_loop()\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mserve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msockets\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msockets\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\python311\\Lib\\asyncio\\runners.py:186\u001b[0m, in \u001b[0;36mrun\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Execute the coroutine and return the result.\u001b[39;00m\n\u001b[0;32m    162\u001b[0m \n\u001b[0;32m    163\u001b[0m \u001b[38;5;124;03mThis function runs the passed coroutine, taking care of\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    182\u001b[0m \u001b[38;5;124;03m    asyncio.run(main())\u001b[39;00m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m events\u001b[38;5;241m.\u001b[39m_get_running_loop() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    185\u001b[0m     \u001b[38;5;66;03m# fail fast with short traceback\u001b[39;00m\n\u001b[1;32m--> 186\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m    187\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124masyncio.run() cannot be called from a running event loop\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    189\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Runner(debug\u001b[38;5;241m=\u001b[39mdebug) \u001b[38;5;28;01mas\u001b[39;00m runner:\n\u001b[0;32m    190\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mrun(main)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: asyncio.run() cannot be called from a running event loop"
     ]
    }
   ],
   "source": [
    "from fastapi import FastAPI\n",
    "import uvicorn\n",
    "app = FastAPI()\n",
    "\n",
    "@app.get(\"/prediction_immobiliere\")  # Corriger le chemin en supprimant les espaces\n",
    "async def predict_params(code_postal=75001, n_pieces=3, surface_habitable=80, latitude=48.8566, longitude=2.3522, date_transaction='2022-01-01'):\n",
    "    # Votre code pour prédire avec les paramètres donnés\n",
    "    return {\"message\": \"Placeholder pour la prédiction immobilière\"}  # Placeholder pour le code réel\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8002)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from fastapi import FastAPI, HTTPException, Depends\n",
    "import sqlite3, uvicorn\n",
    "from datetime import datetime\n",
    "app = FastAPI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@app.get(\"/Prédiciton immobiliere \")\n",
    "async def predict_params(code_postal=75001, n_pieces=3, surface_habitable=80, latitude=48.8566, longitude=2.3522, date_transaction='2022-01-01'):\n",
    "    # Votre code pour prédire avec les paramètres donnés\n",
    "    pass  # Placeholder pour le code réel\n",
    "predict_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    uvicorn.run(app, host=\"127.0.0.1\", port=8002)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
